%TAG !include! ./finetune-base.yaml
---

description: "all the same but with relu activation in cve and wider hidden dim (equal to hid_dim)"

checkpoint: pretrain-transformer-fusion-2:best

module_config:
  model_name: Strats_transformer_fusion_2

  model:
    attention_dropout: 0.2
